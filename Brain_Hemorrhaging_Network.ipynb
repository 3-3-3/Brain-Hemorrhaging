{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "base_dir = '/home/wkeeley/Desktop/Brain-Hemorrhaging'\n",
    "image_dir = os.path.join(base_dir, 'Images')\n",
    "train_dir = os.path.join(image_dir, 'Train_Images')\n",
    "val_dir = os.path.join(image_dir, 'Validation_Images')\n",
    "\n",
    "dcm_dir = os.path.join(base_dir, 'stage_1_train_images')\n",
    "dcm_test_dir = os.path.join(base_dir, 'stage_1_test_images')\n",
    "\n",
    "sub_types = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']\n",
    "\n",
    "sub_train_dirs = []\n",
    "sub_val_dirs = []\n",
    "\n",
    "for i in sub_types:\n",
    "    sub_train_dirs.append(os.path.join(train_dir, i))\n",
    "    sub_val_dirs.append(os.path.join(val_dir, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2723815322667484495\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7409294062892777238\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6599536663486422621\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.268435456"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbranch_a = layers.Conv2D(512, 1, strides=2, activation='relu')(input_tensor)\\n\\nbranch_b = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SpatialDropout2D(0.2)(branch_b)\\nbranch_b = layers.AveragePooling2D(2, strides=2)(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SpatialDropout2D(0.2)(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\nbranch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\\n\\n\\nbranch_c = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\\nbranch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\\nbranch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\\nbranch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\\nbranch_c = layers.SeparableConv2D(512, 4, strides=2, padding='same', activation='relu')(branch_c)\\n\\nbranch_d = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\\nbranch_d = layers.SeparableConv2D(512, 1, activation='relu')(branch_d)\\nbranch_d_1 = layers.SeparableConv2D(512, 1, activation='relu')(branch_d)\\nbranch_d_1 = layers.SeparableConv2D(512, 1, activation='relu')(branch_d_1)\\nbranch_d_1 = layers.BatchNormalization()(branch_d_1)\\nbranch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\\nbranch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\\nbranch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\\nbranch_d_1 = layers.add([branch_d_1, branch_d])\\nbranch_d_1 = layers.SeparableConv2D(512, 1, strides=2, activation='relu')(branch_d_1)\\n\\n\\nout = layers.concatenate([branch_a, branch_b, branch_c, branch_d_1], axis=-1)\\nout = layers.Flatten()(out)\\nprint(out.shape)\\nout = layers.Dense(1, activation='sigmoid')(out)\\nprint(out.shape)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import Input\n",
    "\n",
    "input_tensor = Input(shape=(512, 512, 3))\n",
    "out = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\n",
    "out = layers.Flatten()(out)\n",
    "out = out = layers.Dense(1, activation='sigmoid')(out)\n",
    "'''\n",
    "branch_a = layers.Conv2D(512, 1, strides=2, activation='relu')(input_tensor)\n",
    "\n",
    "branch_b = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SpatialDropout2D(0.2)(branch_b)\n",
    "branch_b = layers.AveragePooling2D(2, strides=2)(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SpatialDropout2D(0.2)(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "branch_b = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_b)\n",
    "\n",
    "\n",
    "branch_c = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\n",
    "branch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\n",
    "branch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\n",
    "branch_c = layers.SeparableConv2D(512, 2, padding='same', activation='relu')(branch_c)\n",
    "branch_c = layers.SeparableConv2D(512, 4, strides=2, padding='same', activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.SeparableConv2D(512, 1, activation='relu')(input_tensor)\n",
    "branch_d = layers.SeparableConv2D(512, 1, activation='relu')(branch_d)\n",
    "branch_d_1 = layers.SeparableConv2D(512, 1, activation='relu')(branch_d)\n",
    "branch_d_1 = layers.SeparableConv2D(512, 1, activation='relu')(branch_d_1)\n",
    "branch_d_1 = layers.BatchNormalization()(branch_d_1)\n",
    "branch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\n",
    "branch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\n",
    "branch_d_1 = layers.SeparableConv2D(512, 4, padding='same', activation='relu')(branch_d_1)\n",
    "branch_d_1 = layers.add([branch_d_1, branch_d])\n",
    "branch_d_1 = layers.SeparableConv2D(512, 1, strides=2, activation='relu')(branch_d_1)\n",
    "\n",
    "\n",
    "out = layers.concatenate([branch_a, branch_b, branch_c, branch_d_1], axis=-1)\n",
    "out = layers.Flatten()(out)\n",
    "print(out.shape)\n",
    "out = layers.Dense(1, activation='sigmoid')(out)\n",
    "print(out.shape)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intraparechymal data Gen.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def callbacks(category):\n",
    "    log_dir = os.path.join(base_dir, category + '_logs')\n",
    "    try:\n",
    "        os.mkdir(log_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(category + '.h5', \n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True),\n",
    "    keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                               histogram_freq=1,\n",
    "                               embeddings_freq=1)\n",
    "    ]\n",
    "    return callbacks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 606833 images belonging to 2 classes.\n",
      "Found 67425 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#epidural\n",
    "epidural_data = train_datagen.flow_from_directory(sub_train_dirs[0],\n",
    "                                           target_size=(512, 512),\n",
    "                                           batch_size=128,\n",
    "                                           class_mode='binary')\n",
    "\n",
    "epidural_val_data = val_datagen.flow_from_directory(sub_val_dirs[0],\n",
    "                                                       target_size=(512, 512),\n",
    "                                                       batch_size=128,\n",
    "                                                       class_mode='binary')\n",
    "epidural_callbacks = callbacks('epidural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wkeeley/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_47 (Separab (None, 512, 512, 512)     2051      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 134217728)         0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 134217729 \n",
      "=================================================================\n",
      "Total params: 134,219,780\n",
      "Trainable params: 134,219,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epidural_model = keras.Model(inputs=input_tensor, output=out)\n",
    "\n",
    "epidural_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "epidural_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = epidural_model.fit_generator(epidural_data,\n",
    "                           steps_per_epoch=100,\n",
    "                           epochs=30,\n",
    "                           callbacks=epidural_callbacks,\n",
    "                           validation_data=epidural_val_data,\n",
    "                           validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraparenchymal_data = train_datagen.flow_from_dir(sub_train_dirs[1],\n",
    "                                           target_size=(512, 512),\n",
    "                                           batch_size=128,\n",
    "                                           class_mode='binary')\n",
    "\n",
    "intraparenchymal_val_data = test_datagen.flow_from_directory(sub_val_dirs[1],\n",
    "                                                       target_size=(512, 512),\n",
    "                                                       batch_size=128,\n",
    "                                                       class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraparenchymal_callbacks = callbacks('intraparenchymal')\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = out.fit_generator(intraparenchymal_data,\n",
    "                           steps_per_epoch=100,\n",
    "                           epochs=30,\n",
    "                           callbacks=intraparenchymal_callbacks,\n",
    "                           validation_data=intraparenchymal_val_data,\n",
    "                           validation_steps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
